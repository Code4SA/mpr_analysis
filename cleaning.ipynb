{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import openpyxl\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# General config\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "display_cols = [\n",
    "    'nappi_code', 'name', 'unit', 'size', 'quantity', 'sep', 'unit_price', 'effective_date'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dataframe\n",
    "\n",
    "data_prefix = 'data/'\n",
    "data_file = 'mpr-cleaned-filled-down.csv'\n",
    "\n",
    "header_names = [\n",
    "    'license_no', 'applicant_name', 'reg_no', 'nappi_code', 'atc_4', 'schedule',\n",
    "    'name', 'active_ingredient', 'strength', 'unit', 'form', 'size', 'quantity', 'man_price',\n",
    "    'logistics_fee', 'vat', 'sep', 'unit_price', 'effective_date', 'status', 'u',\n",
    "    'original_generic','sales_volume'\n",
    "]\n",
    "\n",
    "df = pd.read_csv(\n",
    "    data_prefix + data_file,\n",
    "    sep=',',\n",
    "    header=0,\n",
    "    names=header_names,\n",
    "    parse_dates=['effective_date'])\n",
    "\n",
    "# Make a copy of df to use when exporting\n",
    "original_df = df\n",
    "\n",
    "# Convert some columns to numbers, creating NaNs on errors\n",
    "number_cols = [\n",
    "    'size', 'quantity', 'sep', 'unit_price',\n",
    "    'man_price', 'logistics_fee', 'vat'\n",
    "]\n",
    "\n",
    "df[number_cols] = df[number_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# TODO: \n",
    "# Check number of NaNs before and after converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Before we drop any rows, we create a cell with all the active ingredients\n",
    "# active-strength-unit\n",
    "\n",
    "# We need an ingredient column wiith strengths and units\n",
    "df['full_ingredient'] = df['active_ingredient'] + \" \" + df['strength'] + \" \" + df['unit']\n",
    "df.head()\n",
    "\n",
    "ingredient_df = (df.groupby(\n",
    "    ['nappi_code', 'effective_date', 'full_ingredient'])\n",
    "    .size()\n",
    "    .to_frame('Count')\n",
    "    .reset_index()\n",
    "    .sort_values('nappi_code')\n",
    ")\n",
    "\n",
    "groupby_nappi = ingredient_df.groupby(['nappi_code', 'effective_date'])\n",
    "\n",
    "# .transform casts back to shape of original df the group it's operating on was created from\n",
    "# We combine them with ;; as a seperator\n",
    "combine_ingredients = lambda x: ';;'.join(x.values.tolist())\n",
    "ingredient_df['combined_ingredients'] = groupby_nappi['full_ingredient'].transform(combine_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in df: 71768\n"
     ]
    }
   ],
   "source": [
    "# Drop the data we can't use\n",
    "\n",
    "# Rows with NaN in certain cols\n",
    "drop_nan_cols = ['sep', 'effective_date', 'nappi_code']\n",
    "df = df.dropna(axis=0, subset=drop_nan_cols)\n",
    "\n",
    "\n",
    "# 24 rows with SEP == 0.00, all in 2010. Assuming erroneous\n",
    "idx = df['sep'] != 0\n",
    "df = df.loc[idx, :]\n",
    "\n",
    "# Filter out rows with invvalid NAPPI codes\n",
    "idx = df['nappi_code'].str.len() == 9\n",
    "df = df.loc[idx, :]\n",
    "\n",
    "print \"Rows in df: %s\" % (len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a year colum. This could be done in a better way.\n",
    "\n",
    "get_year = lambda x: pd.Series(x[0:4])\n",
    "df['year'] = df['effective_date'].apply(get_year).apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Medikredit file\n",
    "\n",
    "medikredit_pd_file = 'medikredit20170830.txt'\n",
    "\n",
    "medikredit_nappi_to_size = defaultdict()\n",
    "medikredit_dict = defaultdict(list)\n",
    "\n",
    "with open(data_prefix + medikredit_pd_file) as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        nappi_code = line[10:19]\n",
    "        size_str = line[79:88]\n",
    "        try:\n",
    "            int(nappi_code)\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            size = np.float64(size_str[:-2] + \".\" + size_str[-2:])\n",
    "        except:\n",
    "            size = None\n",
    "        medikredit_nappi_to_size[nappi_code] = size\n",
    "        \n",
    "        medikredit_dict['nappi_code'].append(nappi_code)\n",
    "        medikredit_dict['size'].append(size)\n",
    "        \n",
    "f.close()\n",
    "\n",
    "medikredit_df = pd.DataFrame.from_dict(medikredit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1874"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which items don't occur in the Medikredit data\n",
    "mpr_only_df = df[\n",
    "    (~df['nappi_code'].isin(medikredit_df['nappi_code']))\n",
    "]\n",
    "\n",
    "len(mpr_only_df.groupby(['nappi_code']).size().to_frame('Count').reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce to reliable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop the years we're not interested in\n",
    "df.groupby('year').size()\n",
    "\n",
    "df = df[(df['year'] >= 2008) & (df['year'] <= 2017)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9271"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No. of unique NAPPI codes\n",
    "len(df.groupby('nappi_code').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Frequency of NAPPI codes over the years.\n",
    "# Only use years with many items to determine the frequesncy of occurrrence\n",
    "# 2011 has 1/10th of the records of other years. Exclude in calculating frequency\n",
    "# Check codes in each year: df.groupby('year').size()\n",
    "\n",
    "years = [2009, 2010, 2012, 2013, 2014, 2015, 2016]\n",
    "\n",
    "# Some years occur more than once. Let's get unique instances by grouping by years too for now.\n",
    "# We could also adjust the get_perc function the provide for this\n",
    "\n",
    "nappi_year_df = (\n",
    "    df.groupby(['nappi_code', 'year'])\n",
    "    .size()\n",
    "    .to_frame('Count')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "groupby_nappi = nappi_year_df.groupby('nappi_code')\n",
    "\n",
    "# Transform casts back to shape of original df the group it's operating on was created from\n",
    "calc_freq = lambda x: float(np.sum(x.isin(years))) / len(years)\n",
    "nappi_year_df['freq'] = groupby_nappi['year'].transform(calc_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We only want to merge the perc_occurrence. Group by and drop the other columns\n",
    "freq_df = (\n",
    "    nappi_year_df.groupby(['nappi_code', 'freq'])\n",
    "    .size()\n",
    "    .to_frame('Count')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "del freq_df['Count']\n",
    "\n",
    "# Delete the freq column if it already exists\n",
    "try:\n",
    "    del df['freq']\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "df = pd.merge(\n",
    "    df, freq_df,\n",
    "    how='left', on='nappi_code',\n",
    "    sort=True,\n",
    "    copy=True,\n",
    "    indicator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7584"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NAPPI codes for which the size doesn't change over the years\n",
    "\n",
    "nappi_size_df = (\n",
    "    df.groupby(['nappi_code', 'size'])\n",
    "    .size()\n",
    "    .to_frame('Count')\n",
    "    .reset_index()\n",
    "    .sort_values('nappi_code')\n",
    ")\n",
    "\n",
    "size_change_df = nappi_size_df[nappi_size_df.duplicated('nappi_code', keep=False)]\n",
    "\n",
    "len(df[(~df['nappi_code'].isin(size_change_df['nappi_code']))].groupby(['nappi_code']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6144"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NAPPI codes for which ingredients don't change over years\n",
    "nappi_ingredient_df = (\n",
    "    ingredient_df.groupby(['nappi_code', 'combined_ingredients'])\n",
    "    .size()\n",
    "    .to_frame('Count')\n",
    "    .reset_index()\n",
    "    .sort_values('nappi_code')\n",
    ")\n",
    "\n",
    "ingredient_change_df = nappi_ingredient_df[nappi_ingredient_df.duplicated('nappi_code', keep=False)]\n",
    "\n",
    "len(df[(~df['nappi_code'].isin(ingredient_change_df['nappi_code']))].groupby(['nappi_code']).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3201"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of NAPPI codes in the final dataset\n",
    "# freq > 0.5 translates to at least 4 of the 7 years.\n",
    "\n",
    "len(\n",
    "    df[\n",
    "        (~df['nappi_code'].isin(size_change_df['nappi_code'])) &\n",
    "        (~df['nappi_code'].isin(ingredient_change_df['nappi_code'])) &\n",
    "        (df['freq'] > 0.50) &\n",
    "        (df['nappi_code'].isin(medikredit_df['nappi_code']))\n",
    "    ]\n",
    "    .groupby(['nappi_code'])\n",
    "    .size()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to use for analysis\n",
    "\n",
    "simplified_df = df[\n",
    "    (~df['nappi_code'].isin(size_change_df['nappi_code'])) &\n",
    "    (~df['nappi_code'].isin(ingredient_change_df['nappi_code'])) &\n",
    "    (df['freq'] > 0.50) &\n",
    "    (df['nappi_code'].isin(medikredit_df['nappi_code']))\n",
    "]\n",
    "\n",
    "simplified_df['license_no'].apply(str)\n",
    "\n",
    "simplified_df.to_csv(data_prefix + 'mpr-reliable-data.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# There are some issues during import with the date in this file\n",
    "# Needs to be fixed\n",
    "# Export csv above and save as xlsx before importing\n",
    "\n",
    "# File to use in import of data\n",
    "\n",
    "\n",
    "# export_df = original_df[original_df['nappi_code'].isin(simplified_df['nappi_code'])]\n",
    "\n",
    "# export_df['license_no'].apply(str)\n",
    "\n",
    "# writer = pd.ExcelWriter(data_prefix + 'mpr-data-simplified-for-import.xlsx')\n",
    "# export_df.to_excel(writer, 'Sheet1', encoding='utf-8', index=False)\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
